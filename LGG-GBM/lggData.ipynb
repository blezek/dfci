{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1p/19q</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGG-210</th>\n",
       "      <td>n/n</td>\n",
       "      <td>2</td>\n",
       "      <td>Oligoastrocytoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGG-216</th>\n",
       "      <td>d/d</td>\n",
       "      <td>2</td>\n",
       "      <td>Oligoastrocytoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGG-219</th>\n",
       "      <td>n/n</td>\n",
       "      <td>3</td>\n",
       "      <td>Astrocytoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1p/19q  Grade              Type\n",
       "LGG-210    n/n      2  Oligoastrocytoma\n",
       "LGG-216    d/d      2  Oligoastrocytoma\n",
       "LGG-219    n/n      3       Astrocytoma"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb = load_workbook ( 'TCIA_LGG_cases_159.xlsx')\n",
    "ws = wb.active\n",
    "data = ws.values\n",
    "cols = next(data)[1:]\n",
    "data = list(data)\n",
    "idx = [r[0] for r in data]\n",
    "data = ( islice ( r,1,None) for r in data)\n",
    "\n",
    "df = pd.DataFrame(data,index=idx,columns=cols)\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgg_create_dataset ( dataFilename, dataPath, workbookFilename ):\n",
    "    \"\"\"\n",
    "    Creates an HD5 file containing t1, t2, segmentation and status datasets.\n",
    "    \n",
    "    t1 -- T1 image data by slice contatining a segmentation\n",
    "    t2 -- T2 image data by slice containing a segmentation\n",
    "    segmentation -- segmentation mask\n",
    "    status -- 1p/19q deletion status as 0 or 1\n",
    "    \n",
    "    The datasets are constructed as (N,256,256) for images and (N,1) for status, where N is\n",
    "    the number of slices containing segmentations.\n",
    "    \"\"\"\n",
    "    \n",
    "    wb = load_workbook ( workbookFilename )\n",
    "\n",
    "    f = h5py.File ( dataFilename, \"w\" )\n",
    "    t1 = f.create_dataset ( 't1', (1,256,256), maxshape=(None,None,None),chunks=True, compression=\"gzip\")\n",
    "    t2 = f.create_dataset ( 't2', (1,256,256), maxshape=(None,None,None),chunks=True, compression=\"gzip\")\n",
    "    segmentation = f.create_dataset ( 'segmentation', (1,256,256), maxshape=(None,None,None),chunks=True, compression=\"gzip\", dtype='int8')\n",
    "    status = f.create_dataset ( 'status', (1,1), maxshape=(None,None),chunks=True, compression=\"gzip\", dtype='int8')\n",
    "    \n",
    "    index = 0\n",
    "    dirs = glob.glob ( os.path.join (dataPath, '*') )\n",
    "    for dir in dirs:\n",
    "        imageGlob = glob.glob ( os.path.join ( dir, '*T1*.nii.gz'))\n",
    "        t2Glob = glob.glob ( os.path.join ( dir, '*T2*.nii.gz'))\n",
    "        segmentationGlob = glob.glob ( os.path.join (dir, '*Segmentation.nii.gz') )\n",
    "        \n",
    "        if len(imageGlob) != 1 or len(segmentationGlob) != 1 or len(t2Glob) != 1:\n",
    "            print ( \"skipping {}\".format(dir))\n",
    "            continue\n",
    "        imageFilename = imageGlob[0]\n",
    "        segmentationFilename = segmentationGlob[0]\n",
    "        t2Filename = t2Glob[0]\n",
    "\n",
    "        image = nib.load ( imageFilename )\n",
    "        imageData = np.squeeze ( image.get_data() )\n",
    "        t2File = nib.load ( t2Filename )\n",
    "        t2Data = np.squeeze ( t2File.get_data() )\n",
    "        segmentationFile = nib.load ( segmentationFilename )\n",
    "        segmentationData = np.squeeze ( segmentationFile.get_data() )\n",
    "            \n",
    "        # A few of the images are 256, so resample\n",
    "        if imageData.shape[0] == 512:\n",
    "            imageData = imageData[::2,::2,:]\n",
    "        if t2Data.shape[0] == 512:\n",
    "            t2Data = t2Data[::2,::2,:]\n",
    "        if segmentationData.shape[0] == 512:\n",
    "            segmentationData = segmentationData[::2,::2,:]\n",
    "            \n",
    "        if imageData.shape[0] != 256:\n",
    "            print ( \"skipping {}, data is wrong shape.  Expected 256x256, got {}\".format ( imageFilename, imageData.shape ))\n",
    "            continue\n",
    "            \n",
    "        case = os.path.basename ( dir )\n",
    "        if df.loc[case]['1p/19q'] == 'd/d':\n",
    "            status = 1\n",
    "        else:\n",
    "            status = 0    \n",
    "            \n",
    "        sliceIndex = np.nonzero ( np.sum ( segmentationData, axis=(0,1) ) )[0]\n",
    "\n",
    "        # Enlarge the datasets in the HD5 file\n",
    "        for ds in [t1, t2, segmentation]:\n",
    "            ds.resize ( (index+len(sliceIndex), 256, 256))\n",
    "        status.resize ( (index+len(sliceIndex), 1))\n",
    "        \n",
    "        for s in sliceIndex:\n",
    "            t1[index,:,:] = imageData[:,:,s]\n",
    "            t2[index,:,:] = t2Data[:,:,s]\n",
    "            segmentation[index,:,:] = segmentationData[:,:,s]\n",
    "            status[index,0] = status\n",
    "            index += 1\n",
    "\n",
    "    f.flush()\n",
    "    f.close()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgg_generator ( dataPath, workbookFilename, batchSize=16, seed=1234 ):\n",
    "    \"\"\"\n",
    "    A generator returning T1 slices as the 'X', and segmentations as the 'Y' and status as 'status'.\n",
    "    Only slices with segmentation data are returned.\n",
    "    \n",
    "    Basic algorithm is \n",
    "      1. find all sub-directies of `dataPath`\n",
    "      2. randomly shuffle the order\n",
    "      3. load the image and segmentation\n",
    "      4. find segmented slices\n",
    "      5. fill the bathchX and batchY appropriately\n",
    "      6. yield batchX and batchY when full\n",
    "      7. continue forever\n",
    "    \"\"\"\n",
    "    \n",
    "    wb = load_workbook ( workbookFilename )\n",
    "    \n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    # run forever:\n",
    "    batchIdx = 0\n",
    "    batchX = np.zeros ( ( batchSize, 1, 256, 256 ) )\n",
    "    batchY = np.zeros ( ( batchSize, 1, 256, 256 ) )\n",
    "    batchStatus = np.zeros ( (batchSize, 1 ) )\n",
    "    while True:\n",
    "        dirs = glob.glob ( os.path.join (dataPath, '*') )\n",
    "        random.shuffle ( dirs )\n",
    "        for dir in dirs:\n",
    "            imageGlob = glob.glob ( os.path.join ( dir, '*T1*.nii.gz'))\n",
    "            segmentationGlob = glob.glob ( os.path.join (dir, '*Segmentation.nii.gz') )\n",
    "            \n",
    "            if len(imageGlob) != 1 or len(segmentationGlob) != 1:\n",
    "                print ( \"skipping {}\".format(dir))\n",
    "                continue\n",
    "            imageFilename = imageGlob[0]\n",
    "            segmentationFilename = segmentationGlob[0]\n",
    "            \n",
    "            image = nib.load ( imageFilename )\n",
    "            imageData = np.squeeze ( image.get_data() )\n",
    "            segmentation = nib.load ( segmentationFilename )\n",
    "            segmentationData = np.squeeze ( segmentation.get_data() )\n",
    "            sliceIndex = np.nonzero ( np.sum ( segmentationData, axis=(0,1) ) )[0]\n",
    "            \n",
    "            # A few of the images are 256, so resample\n",
    "            if imageData.shape[0] == 512 and segmentationData.shape[0] == 512:\n",
    "                imageData = imageData[::2,::2,:]\n",
    "                segmentationData = segmentationData[::2,::2,:]\n",
    "            \n",
    "            if imageData.shape[0] != 256:\n",
    "                print ( \"skipping {}, data is wrong shape.  Expected 256x256, got {}\".format ( imageFilename, imageData.shape ))\n",
    "                continue\n",
    "            \n",
    "            case = os.path.basename ( dir )\n",
    "            if df.loc[case]['1p/19q'] == 'd/d':\n",
    "                status = 1\n",
    "            else:\n",
    "                status = 0\n",
    "                    \n",
    "            \n",
    "            for s in sliceIndex:\n",
    "                batchX[batchIdx,0,:,:] = imageData[:,:,s]\n",
    "                batchY[batchIdx,0,:,:] = segmentationData[:,:,s]\n",
    "                batchStatus[batchIdx,0] = status\n",
    "                batchIdx += 1\n",
    "                if batchIdx == batchSize:\n",
    "                    batchIdx = 0\n",
    "                    yield batchX, batchY, batchStatus\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgg_status_generator ( dataPath, workbookFilename, batchSize=16, seed=1234 ):\n",
    "    \"\"\"\n",
    "    A generator returning T1 slices as the 'X', and 1p/19q deletion status as the 'Y'.\n",
    "    Only slices with segmentation data are returned.\n",
    "    \n",
    "    Calls lgg_status_generator\n",
    "    \"\"\"\n",
    "    gen = lgg_generator ( dataPath, workbookFilename, batchSize=batchSize, seed=seed )\n",
    "    while True:\n",
    "        x,y,status = next(gen)\n",
    "        yield x, status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
